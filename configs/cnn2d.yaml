env_config:
  use_condor: True
  env_id: "dwa_param_continuous_costmap-v0"
  seed: 13
  shaping_reward: True
  stack_frame: 4 
  kwargs:
    param_init: [0.5, 1.57, 6, 20, 0.75, 1, 0.3]
    param_list: ["max_vel_x", 
                 "max_vel_theta", 
                 "vx_samples",
                 "vtheta_samples",
                 "path_distance_bias",
                 "goal_distance_bias", 
                 "inflation_radius"]
    world_name: "world_0.world"
    gui: false
    verbose: false
    max_step: 100
    time_step: 1
    slack_reward: 0
    failure_reward: -100
    success_reward: 20
    init_position: [-2, 2, 1.57]
    goal_position: [0, 10, 0]

training_config:
  algorithm: "TD3"
  network: "cnn2d"
  buffer_size: 200000
  actor_lr: 0.0002
  critic_lr: 0.0005
  num_layers: 2
  hidden_size: 256
  exploration_noise_start: 0.5
  exploration_noise_end: 0.1
  exploration_ratio: 1
  pre_collect: 10000

  policy_args:
    tau: 0.005
    gamma: 0.95
    policy_noise: 0.2
    update_actor_freq: 2
    noise_clip: 0.5
    reward_normalization: true
    ignore_done: false
    estimation_step: 4

  training_args:
    max_epoch: 100
    step_per_epoch: 1000
    collect_per_step: 1
    update_per_step: 1
    batch_size: 128

condor_config:
  test_object: "local"  # or "dwa"
  num_actor: 50
  # worlds: [28]
  worlds: [28, 48, 107, 155, 177]
  # worlds: [280, 299, 80, 155, 119, 172, 161, 82, 255, 206, 164, 137, 177, 158, 204, 110, 241, 167, 293, 51, 101, 36, 73, 28, 207, 295, 275, 136, 46, 288, 213, 151, 156, 71, 61, 192, 160, 9, 260, 271, 35, 297, 58, 55, 220, 107, 174, 91, 38, 141]
  test_worlds: [280, 299, 80, 155, 119, 172, 161, 82, 255, 206, 164, 137, 177, 158, 204, 110, 241, 167, 293, 51, 101, 36, 73, 28, 207, 295, 275, 136, 46, 288, 213, 151, 156, 71, 61, 192, 160, 9, 260, 271, 35, 297, 58, 55, 220, 107, 174, 91, 38, 141]
  num_trials: 20
